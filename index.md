Your Name

RTL Design Engineer

Email: your@email - GitHub: github.com/your-username - LinkedIn: linkedin.com/in/your-handle

​
Education

Arizona State University — MS, Computer Engineering — Aug 2024 – May 2026

    Coursework: Computer Architecture; Advanced Digital Design and Verification; Algo/HW Co‑design/Design Automation for AI Hardware

    ​

Bharati Vidyapeeth University — BTech, Electronics and Telecomm Engineering — Jun 2018 – Aug 2022

    Coursework: Microprocessors and Microcontrollers; VLSI Design; Digital Circuits

    ​

Professional Experience

Arizona State University — Graduate Student Researcher — Aug 2025 – Present

    Researched on‑the‑fly cache compression in modern architectures to improve hit rate; implemented methodology on a RISC‑V CPU in Verilog

​

Profiled memory access patterns for SQLite3, STREAM, and ML workloads (DBSCAN, CNN, PCA, KMeans) using the Intel Pin instrumentation tool

    ​

Manjeera Digital Systems — RTL Design Engineer Trainee — Oct 2022 – Mar 2024

    Implemented floating‑point support and 20 custom vector instructions for a DSP; prototyped and tested on Intel PAC D5005 for space applications

​

Improved microarchitecture for FP operations and automated simulation with Tcl scripts

​

Achieved ~14% higher clock speed (~800 MHz) on Intel Stratix‑10 MX/NX FPGAs; collaborated with verification to validate datapath and basic STA timing closure

​

Enhanced DMA IP to better support the DSP design, yielding ~20% higher data transfer speed

    ​

Skills

Programming/HDLs/Scripting: Python, C, Verilog, SystemVerilog
​
EDA/ASIC Tools: Intel Pin, Quartus, ModelSim, AMD Vivado, Linux, Synopsys DC, Verdi, Gem5​
Technology: Intel Stratix‑10 MX/NX/SX, Arria‑10 GX, Terasic DE10‑Lite, AMD Zynq‑7000

​
Academic Projects

Multi‑level Cache Design in Software and RTL — Sep 2025 – Present

    Built Python models for direct‑mapped, set‑associative, and fully associative caches to evaluate compression algorithms across configurations

​

Designed a multi‑level cache hierarchy in RTL with compression logic; achieved >31% higher hit rate than traditional baselines; validated with Intel Pin access patterns

    ​

Profiling ML Models on CPU and GPU — Aug 2025

    Implemented VGG‑8, LeNet‑5, and AlexNet‑5 in Python; used Google Colab with NVIDIA T4 GPU

​

Profiled inference latency vs batch size and performed roofline analysis on CPU and GPU; improved training and test accuracy using trainability and expressivity methods (+12% and +7%)

    ​

Branch Predictors in RISC‑V — Jul 2025

    Integrated 2‑bit, gselect, and gshare branch predictors in a 5‑stage RISC‑V CPU; fixed control‑flow updates for predicted and actual targets

​

Wrote simulation tests and measured ~17% average performance improvement

    ​

32‑bit MIPS Processor Design and Verification — May 2025

    Implemented a 5‑stage MIPS with stall, flush, and hazard units; added a multi‑cycle instruction and resolved pipeline hazards in ModelSim

​

Built a constrained‑random instruction generator and achieved ~80% functional coverage; synthesized with Synopsys DC

    ​

About

Interested in RTL design roles focused on caches, memory systems, and CPU microarchitecture; open to opportunities in ASIC/FPGA design and verification.
​
